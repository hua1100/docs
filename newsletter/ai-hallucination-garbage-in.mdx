---
title: "幻覺不只 AI 有，我們都要學不要倒垃圾給 AI"
description: "從 SDD（規格驅動開發）到 AI 輔助沉浸式體驗，探討把話寫清楚、內容與形式之辯，以及 AI 如何為條漫自動配樂。"
keywords: ["SDD", "規格驅動開發", "AI幻覺", "Podcast自動化", "AI配樂", "寫作規格", "Context Engineering"]
---

## 一、把話寫清楚

這兩周都在了解 SDD（Specification-Driven Development，規格驅動開發），還用這套方法做了貪吃蛇、俄羅斯方塊兩人對戰版等復古的小遊戲，幾乎 one-shot 完成的低出錯率，讓我對「把話寫清楚」的重要性有更深一層的認識。

> 工程師沒辦法把話寫清楚，所以跳過規格直接寫 Code。
> 麻瓜沒辦法把話寫清楚，所以 AI 幻覺連篇。

過去的開發流程以程式碼為核心，規格、需求文件只是補充資料，並不會隨著專案進度更新，程式碼與文件就漸行漸遠。SDD 的出現翻轉了這套想法，轉而建立規格為真相的流程，規格不再僅是參考指引，而是可以被測試、被執行，並最終驅動程式碼的指令。

這是文組人一直都在做的事——寫文件，只是現在文件是 AI 在看。當文字不夠清晰、邏輯不夠嚴謹，AI 就會想辦法合理化你的描述。所謂幻覺，也只是 AI 在努力讓倒垃圾進去的東西，吐出的不是垃圾，而是有邏輯的填充物（Garbage in, logical out）。

### 撰寫清晰規格的原則

這四條原則每一條都可以對應到寫作：

1. **每條規格都應具備驗收條件**，驗收條件可直接對應測試名稱，測試通過即規格被滿足；就像寫作中每個論點都應有可驗證的支持證據。
2. **範例優於描述**，不要形容，要舉例；如同寫作強調用具體案例說明抽象概念。
3. **採用 Given/When/Then 結構撰寫**（行為驅動開發語法）；邏輯鏈與寫作強調用具體、有脈絡的情境說故事的要求一致。
4. **所有規格文件中的角色名稱必須統一**；就像寫作中同一概念應使用相同術語，且人稱視角要一致。

<Warning>
人類比 AI 的幻覺還大，小心自以為學會了。累積更多經驗、了解更多細節，才能超脫規則自成一格，一切回到你是不是有判斷力。
</Warning>

## 二、內容重要還是形式？

最近想嘗試把電子報文章自動化轉成雙人對談的 Podcast，難的是企劃，同一個議題用不同的方式說故事。

過去在媒體接觸的資深媒體人，往往都會認為文字為王，有一股要靠內容取勝的傲氣，不願意在行銷包裝上花資源。AI 讓我們多了很多說故事的方法，加入不同的感官，除了視覺還有聽覺，我們可以自由在各種格式裡轉換，沒有理由不多做一點擴大打擊面的形式。

這題還在研究階段，這類工作流提示詞的品質是成功關鍵，以下兩筆資料可以參考：

- [Meta NotebookLlama 開源提示詞](https://github.com/meta-llama/llama-cookbook/blob/main/end-to-end-use-cases/NotebookLlama/README.md) — Meta 模仿 Google NotebookLM 推出的架構，有把系統提示詞開源
- [ElevenLabs 語音提示詞規則](https://elevenlabs.io/docs/best-practices/prompting/eleven-v3) — 讓生成的語音更有情感，例如有笑聲、會嘆氣、停頓思考等

## 三、AI 輔助沉浸式體驗

參加 AI 小聚，遊戲橘子的 AI Researcher Intern Andrew 分享了如何讓 AI 像專業配樂師一樣，自動看懂條漫內容，生成配樂與音效。流程分成三個模組實現：

**背景音樂 pipeline**
1. 場景分割：先用 GPT-4.1 把漫畫頁面切分成不同的場景
2. BGM 分析：分析每個場景的圖片，用 GPT-4.1 生成「以標籤為基礎的音樂說明文字」
3. 音樂生成：把這些說明文字交給 Magenta RT 模型，自動生成符合場景氛圍的背景音樂

**音效 pipeline**
1. 音效分析：用 GPT-4.1 分析圖片，找出需要配音效的地方，並生成「(圖片編號, 音效描述)配對」
2. 音效生成：使用 Stable-Audio-Open-1.0 模型，根據描述生成對應的音效

**時間點偵測 pipeline**
1. 人物和格子偵測：使用 Manga Whisper v3 模型，偵測漫畫中每個格子的位置和人物出現的位置
2. 產生座標資訊：輸出每個格子和人物的邊界框座標，用來確定音效該在什麼時間點播放

<Note>
結合三個模組，就能讓背景音樂根據場景變化自動切換，在對應的網格播放音效。這套切割模組的方式蠻值得參考的，尤其是時間點偵測模組的設計。

文字同樣也是一幀一幀往下滑的形式，有沒有機會在往下滑的同時，同步生成配樂、圖片，甚至影片？未來的內容體驗在 AI 的發展下實在是大開腦洞！
</Note>
